{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in d:\\saurabh data hp laptop\\hp user\\downloads\\python\\lib\\site-packages (1.22.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\saurabh data hp laptop\\hp user\\downloads\\python\\lib\\site-packages (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.18.5; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\" in d:\\saurabh data hp laptop\\hp user\\downloads\\python\\lib\\site-packages (from pandas) (1.22.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\saurabh data hp laptop\\hp user\\downloads\\python\\lib\\site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in d:\\saurabh data hp laptop\\hp user\\downloads\\python\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\saurabh data hp laptop\\hp user\\downloads\\python\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in d:\\saurabh data hp laptop\\hp user\\downloads\\python\\lib\\site-packages (1.21.4)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in d:\\saurabh data hp laptop\\hp user\\downloads\\python\\lib\\site-packages (from boto3) (0.5.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in d:\\saurabh data hp laptop\\hp user\\downloads\\python\\lib\\site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.25.0,>=1.24.4 in d:\\saurabh data hp laptop\\hp user\\downloads\\python\\lib\\site-packages (from boto3) (1.24.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in d:\\saurabh data hp laptop\\hp user\\downloads\\python\\lib\\site-packages (from botocore<1.25.0,>=1.24.4->boto3) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in d:\\saurabh data hp laptop\\hp user\\downloads\\python\\lib\\site-packages (from botocore<1.25.0,>=1.24.4->boto3) (1.25.11)\n",
      "Requirement already satisfied: six>=1.5 in d:\\saurabh data hp laptop\\hp user\\downloads\\python\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.4->boto3) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in d:\\saurabh data hp laptop\\hp user\\downloads\\python\\lib\\site-packages (4.1.2)\n",
      "Requirement already satisfied: Cython==0.29.23 in d:\\saurabh data hp laptop\\hp user\\downloads\\python\\lib\\site-packages (from gensim) (0.29.23)\n",
      "Requirement already satisfied: numpy>=1.17.0 in d:\\saurabh data hp laptop\\hp user\\downloads\\python\\lib\\site-packages (from gensim) (1.22.2)\n",
      "Requirement already satisfied: scipy>=0.18.1 in d:\\saurabh data hp laptop\\hp user\\downloads\\python\\lib\\site-packages (from gensim) (1.5.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in d:\\saurabh data hp laptop\\hp user\\downloads\\python\\lib\\site-packages (from gensim) (5.2.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in d:\\saurabh data hp laptop\\hp user\\downloads\\python\\lib\\site-packages (1.22.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  pandas as pd\n",
    "import boto3\n",
    "from boto3.dynamodb.conditions import Attr, Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from lexicalrichness import LexicalRichness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "_TableName_ =\"converz-dev-media-in\"\n",
    "Primary_Column_Name=\"PK\"\n",
    "Primary_Key = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('dynamodb',region_name=\"ap-south-1\",aws_access_key_id='AKIA2SGYSMCCCRLN7OVU',\n",
    "                     aws_secret_access_key='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')\n",
    "DB = boto3.resource('dynamodb',region_name=\"ap-south-1\",aws_access_key_id='AKIA2SGYSMCCCRLN7OVU',\n",
    "                     aws_secret_access_key='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')\n",
    "table=DB.Table(_TableName_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "response =table.query(Select=\"ALL_ATTRIBUTES\",KeyConditionExpression=Key('PK').eq('media#01FYB6VYE0JCHZPEPBGDBQ7YKY') & Key('SK').begins_with('transcript') )\n",
    "#response=table.scan()\n",
    "data = response[\"Items\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript_created_on</th>\n",
       "      <th>media_id</th>\n",
       "      <th>transcript_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>transcript_start_time</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>SK</th>\n",
       "      <th>transcript_word_items</th>\n",
       "      <th>PK</th>\n",
       "      <th>transcript_end_time</th>\n",
       "      <th>transcript_speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1647497278.768229007720947265625</td>\n",
       "      <td>01FYB6VYE0JCHZPEPBGDBQ7YKY</td>\n",
       "      <td>Hi everyone,</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1200</td>\n",
       "      <td>01FYB7TX9GP4BMVRN4WSRRMYWV</td>\n",
       "      <td>transcript#01FYB7TX9GP4BMVRN4WSRRMYWV</td>\n",
       "      <td>[\\n    {\\n        \"word_id\": 0,\\n        \"word...</td>\n",
       "      <td>media#01FYB6VYE0JCHZPEPBGDBQ7YKY</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1647497279.0272541046142578125</td>\n",
       "      <td>01FYB6VYE0JCHZPEPBGDBQ7YKY</td>\n",
       "      <td>welcome today to the creative Community scheme...</td>\n",
       "      <td>positive</td>\n",
       "      <td>3500</td>\n",
       "      <td>01FYB7TXHJDRD0PD575SBVVVEA</td>\n",
       "      <td>transcript#01FYB7TXHJDRD0PD575SBVVVEA</td>\n",
       "      <td>[\\n    {\\n        \"word_id\": 0,\\n        \"word...</td>\n",
       "      <td>media#01FYB6VYE0JCHZPEPBGDBQ7YKY</td>\n",
       "      <td>14700</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1647497279.087502956390380859375</td>\n",
       "      <td>01FYB6VYE0JCHZPEPBGDBQ7YKY</td>\n",
       "      <td>Bethany Ralston and Adrian Clothier from creat...</td>\n",
       "      <td>positive</td>\n",
       "      <td>15800</td>\n",
       "      <td>01FYB7TXKFN8EF2CDFGG3J4XYT</td>\n",
       "      <td>transcript#01FYB7TXKFN8EF2CDFGG3J4XYT</td>\n",
       "      <td>[\\n    {\\n        \"word_id\": 0,\\n        \"word...</td>\n",
       "      <td>media#01FYB6VYE0JCHZPEPBGDBQ7YKY</td>\n",
       "      <td>24600</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1647497279.1494181156158447265625</td>\n",
       "      <td>01FYB6VYE0JCHZPEPBGDBQ7YKY</td>\n",
       "      <td>I will hand you over to</td>\n",
       "      <td>negative</td>\n",
       "      <td>25000</td>\n",
       "      <td>01FYB7TXND4TZJX584F3G5K0S8</td>\n",
       "      <td>transcript#01FYB7TXND4TZJX584F3G5K0S8</td>\n",
       "      <td>[\\n    {\\n        \"word_id\": 0,\\n        \"word...</td>\n",
       "      <td>media#01FYB6VYE0JCHZPEPBGDBQ7YKY</td>\n",
       "      <td>26200</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1647497279.2099640369415283203125</td>\n",
       "      <td>01FYB6VYE0JCHZPEPBGDBQ7YKY</td>\n",
       "      <td>Bethany.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>26200</td>\n",
       "      <td>01FYB7TXQ9GXMJ9ZRWMPHRYA9J</td>\n",
       "      <td>transcript#01FYB7TXQ9GXMJ9ZRWMPHRYA9J</td>\n",
       "      <td>[\\n    {\\n        \"word_id\": 0,\\n        \"word...</td>\n",
       "      <td>media#01FYB6VYE0JCHZPEPBGDBQ7YKY</td>\n",
       "      <td>26800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               transcript_created_on                    media_id  \\\n",
       "0   1647497278.768229007720947265625  01FYB6VYE0JCHZPEPBGDBQ7YKY   \n",
       "1     1647497279.0272541046142578125  01FYB6VYE0JCHZPEPBGDBQ7YKY   \n",
       "2   1647497279.087502956390380859375  01FYB6VYE0JCHZPEPBGDBQ7YKY   \n",
       "3  1647497279.1494181156158447265625  01FYB6VYE0JCHZPEPBGDBQ7YKY   \n",
       "4  1647497279.2099640369415283203125  01FYB6VYE0JCHZPEPBGDBQ7YKY   \n",
       "\n",
       "                                     transcript_text sentiment  \\\n",
       "0                                       Hi everyone,   neutral   \n",
       "1  welcome today to the creative Community scheme...  positive   \n",
       "2  Bethany Ralston and Adrian Clothier from creat...  positive   \n",
       "3                            I will hand you over to  negative   \n",
       "4                                           Bethany.   neutral   \n",
       "\n",
       "  transcript_start_time               transcript_id  \\\n",
       "0                  1200  01FYB7TX9GP4BMVRN4WSRRMYWV   \n",
       "1                  3500  01FYB7TXHJDRD0PD575SBVVVEA   \n",
       "2                 15800  01FYB7TXKFN8EF2CDFGG3J4XYT   \n",
       "3                 25000  01FYB7TXND4TZJX584F3G5K0S8   \n",
       "4                 26200  01FYB7TXQ9GXMJ9ZRWMPHRYA9J   \n",
       "\n",
       "                                      SK  \\\n",
       "0  transcript#01FYB7TX9GP4BMVRN4WSRRMYWV   \n",
       "1  transcript#01FYB7TXHJDRD0PD575SBVVVEA   \n",
       "2  transcript#01FYB7TXKFN8EF2CDFGG3J4XYT   \n",
       "3  transcript#01FYB7TXND4TZJX584F3G5K0S8   \n",
       "4  transcript#01FYB7TXQ9GXMJ9ZRWMPHRYA9J   \n",
       "\n",
       "                               transcript_word_items  \\\n",
       "0  [\\n    {\\n        \"word_id\": 0,\\n        \"word...   \n",
       "1  [\\n    {\\n        \"word_id\": 0,\\n        \"word...   \n",
       "2  [\\n    {\\n        \"word_id\": 0,\\n        \"word...   \n",
       "3  [\\n    {\\n        \"word_id\": 0,\\n        \"word...   \n",
       "4  [\\n    {\\n        \"word_id\": 0,\\n        \"word...   \n",
       "\n",
       "                                 PK transcript_end_time transcript_speaker  \n",
       "0  media#01FYB6VYE0JCHZPEPBGDBQ7YKY                2000                  1  \n",
       "1  media#01FYB6VYE0JCHZPEPBGDBQ7YKY               14700                  3  \n",
       "2  media#01FYB6VYE0JCHZPEPBGDBQ7YKY               24600                  3  \n",
       "3  media#01FYB6VYE0JCHZPEPBGDBQ7YKY               26200                  3  \n",
       "4  media#01FYB6VYE0JCHZPEPBGDBQ7YKY               26800                  1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class textRichness:\n",
    "        def __init__(self,dataframe,column_name):\n",
    "            self.dataframe=dataframe\n",
    "            self.column_name=column_name\n",
    "        def f(self):\n",
    "        #    x = input(\"Enter the data frame column\")\n",
    "            text = re.sub(r'\\[[0-9]*\\]',' ',str(self.dataframe[self.column_name]))\n",
    "            text = re.sub(r'\\s+',' ',text)\n",
    "            text = text.lower()\n",
    "            text = re.sub(r'\\d',' ',text)\n",
    "            text = re.sub(r'\\s+',' ',text)\n",
    "            text = re.sub(r'[^\\w\\s]', '', text)\n",
    "            lex = LexicalRichness(text)\n",
    "            word_count =lex.words\n",
    "            print(f' word count:{word_count }')\n",
    "            type_token_ratio= lex.ttr\n",
    "            print(f' type-token ratio (TTR):{type_token_ratio }')\n",
    "            root_type_token_ratio = lex.rttr\n",
    "            print(f' root type-token ratio (RTTR) of text:{root_type_token_ratio }')\n",
    "            corrected_type_token_ratio=lex.cttr\n",
    "            print(f' corrected type-token ratio (CTTR):{corrected_type_token_ratio }')\n",
    "            mean_segmental_type_token_ratio = lex.msttr(segment_window=25)\n",
    "            print(f' mean segmental type-token ratio (MATTR):{mean_segmental_type_token_ratio}')\n",
    "            moving_average_type_token_ratio=lex.mattr(window_size=25)\n",
    "            print(f' moving average type-token ratio (MATTR):{moving_average_type_token_ratio}')\n",
    "            Measure_of_Textual_Lexical_Diversity=lex.mtld(threshold=0.72)\n",
    "            print(f' Measure of Textual Lexical Diversity:{Measure_of_Textual_Lexical_Diversity}')\n",
    "            hypergeometric_distribution_diversity=lex.hdd(draws=42)\n",
    "            print(f' hypergeometric distribution diversity : {hypergeometric_distribution_diversity}')\n",
    "            Herdan_lexical_diversity_measure=lex.Herdan\n",
    "            print(f' Herdan lexical diversity measure : {Herdan_lexical_diversity_measure}')\n",
    "            Summer_lexical_diversity_measure = lex.Summer\n",
    "            print(f' Summer lexical diversity measure : {Summer_lexical_diversity_measure}')\n",
    "            Dugast_lexical_diversity_measure= lex.Dugast\n",
    "            print(f' Dugast lexical diversity measure : {Dugast_lexical_diversity_measure}')\n",
    "            Maas_lexical_diversity_measure = lex.Maas\n",
    "            print(f' Maas lexical diversity measure: {Maas_lexical_diversity_measure}')\n",
    "\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=textRichness(df,\"transcript_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " word count:60\n",
      " type-token ratio (TTR):0.8666666666666667\n",
      " root type-token ratio (RTTR) of text:6.713171133426189\n",
      " corrected type-token ratio (CTTR):4.74692883171144\n",
      " mean segmental type-token ratio (MATTR):0.94\n",
      " moving average type-token ratio (MATTR):0.9488888888888896\n",
      " Measure of Textual Lexical Diversity:126.00000000000004\n",
      " hypergeometric distribution diversity : 0.9001558542762528\n",
      " Herdan lexical diversity measure : 0.96504914487143\n",
      " Summer lexical diversity measure : 0.9747615750095074\n",
      " Dugast lexical diversity measure : 117.14576216120243\n",
      " Maas lexical diversity measure: 0.008536373672859934\n"
     ]
    }
   ],
   "source": [
    "a.f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myworkspace",
   "language": "python",
   "name": "myworkspace"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
